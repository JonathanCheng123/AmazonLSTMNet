{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team E AmazonReview LSTMNet",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonathanCheng123/AmazonLSTMNet/blob/main/Team_E_AmazonReview_LSTMNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEGDt4hrKGMu"
      },
      "source": [
        "# TEAM E - AMAZON REVIEWS\n",
        "\n",
        "In this project you work on Amazon food review from customers, and try to predict whether a review is positive or negative. \n",
        "\n",
        "**Dataset:**\n",
        "\n",
        "The dataset contains more than 500K reviews with scores given by customers, number of upvotes & total votes to those comments. The dataset has ‘Score’ label which is given by customers to each product. Scores range from 1-5. \n",
        "\n",
        "For doing a binary classification, you need to get rid of score ‘3’ reviews (neutral) and separate the remaining reviews into binary class (1 = positive, 0 = negative)\n",
        "\n",
        "**Size:** 394,375 instances\n",
        "\n",
        "**Classes:** 2 (Positive = 1 , Negative = 0 )\n",
        "\n",
        "**Class skewness:**\n",
        "\n",
        "instance belonging to Negative class: 61,625\n",
        "\n",
        "instances belonging to Positive class: 332,750\n",
        "\n",
        "**Note: Reviews are skewed towards positive.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZAIm_aAJ4p2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import string\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "import keras\n",
        "import gensim\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eENmBBLELQJW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYp_6vnLLQzB"
      },
      "source": [
        "text = pd.read_csv(\"/content/drive/My Drive/Cosmos/train.csv\",delimiter='\\t', usecols=[10])\n",
        "scored = pd.read_csv(\"/content/drive/My Drive/Cosmos/train.csv\",delimiter='\\t', usecols=[7])\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Cosmos/train.csv\",delimiter='\\t', usecols=[10])\n",
        "testscored = pd.read_csv(\"/content/drive/My Drive/Cosmos/train.csv\",delimiter='\\t', usecols=[7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYF1zn9Idi0-"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "def preprocess(s):\n",
        "  return lemmatizer.lemmatize(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWCT_T2yIO4d"
      },
      "source": [
        "cutoff=120000\n",
        "scorecutoff=50000\n",
        "features=15000\n",
        "vocab_size = 10000\n",
        "max_length = 16952 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLtwgJD0yXS"
      },
      "source": [
        "reviews=text.Text.tolist()\n",
        "testreviews = test.Text.tolist()\n",
        "score = scored.to_numpy().reshape(len(scored),1,1)\n",
        "testscore = testscored.to_numpy().reshape(len(testscored),1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEY1W0UlWcrL"
      },
      "source": [
        "score1 = []\n",
        "reviews1=[]\n",
        "c=0\n",
        "for i in range(len(reviews)):\n",
        "  if(score[i]==0):\n",
        "    if(c<30000):\n",
        "      c += 1\n",
        "      score1.append(score[i])\n",
        "      reviews1.append(reviews[i])\n",
        "c=0    \n",
        "for i in range(len(reviews)):\n",
        "  if(score[i]==1):\n",
        "    if(c<90000):\n",
        "      c += 1\n",
        "      score1.append(score[i])\n",
        "      reviews1.append(reviews[i])\n",
        "score = score1\n",
        "reviews = reviews1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pC0xrX2iRjX"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words=stop, analyzer = 'word',max_features=features, dtype=np.float32, preprocessor=preprocess)\n",
        "vectorizer.fit(text.Text)\n",
        "\n",
        "score = np.array(score)\n",
        "testscore = testscored.to_numpy()[0:scorecutoff].reshape(scorecutoff,1,1)\n",
        "\n",
        "X_trainv = np.array([vectorizer.transform([a]).astype('float32').toarray() for a in reviews])\n",
        "X_testv = np.array([vectorizer.transform([a]).astype('float32').toarray() for a in test.Text.tolist()[:scorecutoff]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFFhVP3ToW8c"
      },
      "source": [
        "X_train = np.squeeze(X_trainv)\n",
        "X_train=X_train.reshape((len(X_train),1,features))\n",
        "X_test = np.squeeze(X_testv).reshape(scorecutoff, 1, features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xs3ntFjVV3j"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.LSTM(50, input_shape=(1,15000),return_sequences = True, recurrent_regularizer=tf.keras.regularizers.l2(0.005), kernel_initializer = 'glorot_normal', activation = 'relu'))\n",
        "# model.add(layers.LSTM(64, return_sequences = True, kernel_initializer = 'glorot_normal', activation = 'relu', recurrent_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model.add(layers.TimeDistributed(layers.Dense(16,activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005))))\n",
        "model.add(layers.TimeDistributed(layers.Dense(32,activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer=tf.train.AdamOptimizer(0.0002))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwGFiwMqzK0I"
      },
      "source": [
        "model.summary()\n",
        "print (\"Inputs: {}\".format(model.input_shape))\n",
        "print (\"Outputs: {}\".format(model.output_shape))\n",
        "print (\"Actual input: {}\".format(X_train.shape))\n",
        "print (\"Actual output: {}\".format(score.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq8kaTbYqWxk"
      },
      "source": [
        "a=model.fit(X_train, score, epochs=15,batch_size=256, validation_data=[X_test, testscore])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7_u3qOrQgcT"
      },
      "source": [
        "model.evaluate(X_test,testscore,batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_xy7Nct48tZ"
      },
      "source": [
        "val_acc = a.history['val_acc']\n",
        "train_acc = a.history['acc']\n",
        "epoch_count = range(1, len(val_acc) + 1)\n",
        "plt.plot(epoch_count, train_acc, 'b')\n",
        "plt.plot(epoch_count, val_acc, 'r')\n",
        "plt.legend(['Training Accuracy', 'Test Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsFLc6RH6yUj"
      },
      "source": [
        "training_loss = a.history['loss']\n",
        "val_loss = a.history['val_loss']\n",
        "epoch_count = range(1, len(val_loss) + 1)\n",
        "plt.plot(epoch_count, val_loss, 'b')\n",
        "plt.plot(epoch_count, training_loss, 'r')\n",
        "plt.legend(['Validation Loss', 'Training Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECOOwN6vOrE7"
      },
      "source": [
        "def process(a):\n",
        "  v=vectorizer.transform([a]).toarray()\n",
        "  v=v.reshape(1,1,features)\n",
        "  return v\n",
        "\n",
        "string = input('Enter a review: ')\n",
        "a = model.predict(process(string),batch_size=1,verbose = 0)\n",
        "print(a)\n",
        "if(a[0]>0.5):\n",
        "  print(\"Positive review\")\n",
        "else:\n",
        "  print(\"Negative review\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwg2ZoTdOw4p"
      },
      "source": [
        "model.save('drive/My Drive/model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v562yiO4hvMq"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('drive/My Drive/model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC5cJiblVXaV"
      },
      "source": [
        "print(text[0])\n",
        "print(textarray[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}